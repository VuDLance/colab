{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFRfciviIPnF9kHU9tDqoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VuDLance/colab/blob/main/aai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN9bkKAk2GBL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "good_frames = 'C:/Users/OS/Pictures/ReCover'\n",
        "bad_frames = 'C:/Users/OS/Pictures/Saved Pictures'"
      ],
      "metadata": {
        "id": "NyAl5fZc5WW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_frames = []\n",
        "for file in tqdm (sorted (os.listdir (good_frames))):\n",
        "  if any(extension in file for extension in ['.jpg', '.jpeg', '.png']):\n",
        "         image = tf.keras.preprocessing.image.load_img(good_frames + '/' + file, target_size=(128,128))\n",
        "         image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n",
        "          clean_frames.append(image)\n",
        "\n",
        "clean_frames = np.array(clean_frames)\n",
        "blurry_frames = []\n",
        "for file in tqdm (sorted (os.listdir(bad_frames))):\n",
        "    if any (extension in file for extension in ['.jpg', 'jpeg', '.png']):\n",
        "        image = tf.keras.preprocessing.image.load_img (bad_frames + '/' + file, target_size=(128,128))\n",
        "        image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n",
        "        blurry_frames.append(image)\n",
        "\n",
        "blurry_frames = np.array(blurry_frames)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "jTwC2g_e51UZ",
        "outputId": "1a429725-1ee2-4050-daea-16db78091b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-7ab3b37302f7>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32')/255\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K\n",
        "\n",
        "seed = 21\n",
        "random.seed\n",
        "seed\n",
        "np.random.seed = seed\n"
      ],
      "metadata": {
        "id": "_fChBBllBv4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = clean_frames;\n",
        "y = blurry_frames;\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gDzsX1ikB9AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0].shape)\n",
        "print(y_train[0].shape)"
      ],
      "metadata": {
        "id": "9WcXGMtrCQ3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = random.randint(0, len(clean_frames)-1)\n",
        "print(r)\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust (hspace=0.1, wspace=0.2)\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(clean_frames[r])\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.imshow(blurry_frames[r])"
      ],
      "metadata": {
        "id": "U07QmOMbC6Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Network Parameters\n",
        "input_shape = (128, 128, 3)\n",
        "batch_size = 32\n",
        "kernel_size = 3\n",
        "latent_dim= 256\n",
        "# Encoder/Decoder number of CNN layers and filters per layer\n",
        "layer_filters = [64, 128, 256]\n"
      ],
      "metadata": {
        "id": "of6Tv_A3EORN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape = input_shape, name= 'encoder_input')\n",
        "x = inputs"
      ],
      "metadata": {
        "id": "RybW0wjgEmep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filters in layer_filters:\n",
        "  x = Conv2D(filters=filters,\n",
        "              kernel_size=kernel_size,\n",
        "              strides=2,\n",
        "              activation='relu',\n",
        "              padding='same')(x)\n",
        "shape = K.int_shape(x)\n",
        "x = Flatten()(x)\n",
        "latent = Dense(latent_dim, name='latent_vector')(x)\n"
      ],
      "metadata": {
        "id": "q--GaoI8E2Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(inputs, latent, name='encoder')\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "r3Jke04iFVrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
        "x = Dense(shape[1]*shape [2]*shape [3])(latent_inputs)\n",
        "x = Reshape((shape [1], shape [2], shape [3]))(x)\n",
        "for filters in layer_filters [::-1):\n",
        "    x = Conv2DTranspose(filters-filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=2,\n",
        "                        activation='relu',\n",
        "                        padding='same')(x)\n",
        "outputs = Conv2DTranspose(filters=3,\n",
        "                          kernel_size=kernel_size,\n",
        "                          activation='sigmoid',\n",
        "                          padding='same',\n",
        "                          name='decoder_output')(x)"
      ],
      "metadata": {
        "id": "oAUEXLvyGrjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "21VtmpzKHd0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "LLC8_ucaIiLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(loss='mse', optimizer='adam', metrics=[\"acc\"])"
      ],
      "metadata": {
        "id": "hrNUegGRIufk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                                cooldown=0,\n",
        "                                patience=5,\n",
        "                                verbose=1,\n",
        "                                min_lr=0.5e-6)\n"
      ],
      "metadata": {
        "id": "cnD5_aW4I8x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [lr_reducer]\n",
        "history = autoencoder.fit(blurry_frames,\n",
        "                          clean_frames,\n",
        "                          validation_data=(blurry_frames, clean_frames),\n",
        "                          epochs=100,\n",
        "                          batch_size=batch_size,\n",
        "                          callbacks=callbacks)"
      ],
      "metadata": {
        "id": "gaUmnnpfKD_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n \tInput\t\tGround Truth\t\t\tPredicted Value\")\n",
        "\n",
        "for i in range(3):\n",
        "\n",
        "r = random.randint(0, len(clean_frames)-1)\n",
        "\n",
        "x, y = blurry_frames [r], clean_frames [r]\n",
        "x_inp=x.reshape(1,128,128,3)\n",
        "result = autoencoder.predict(x_inp)\n",
        "result = result.reshape(128,128,3)\n",
        "\n",
        "fig = plt.figure(figsize=(12,10))\n",
        "fig.subplots_adjust(hspace=0.1, wspace=0.2)\n",
        "\n",
        "ax = fig.add_subplot(1, 3, 1)\n",
        "ax.imshow(x)\n",
        "\n",
        "ax = fig.add_subplot(1, 3, 2)\n",
        "ax.imshow(y)\n",
        "\n",
        "ax = fig.add_subplot(1, 3, 3)\n",
        "plt.imshow(result)"
      ],
      "metadata": {
        "id": "_VktJ8GaLnWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(np.arange(0, 101, 25))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GKRWefW9MxU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(np.arange(0, 101, 25))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TXVcJwl5Myzq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}